import os
import json
import time
import hashlib
import logging
from collections import defaultdict

import pydicom
import SimpleITK as sitk
import nibabel as nib
import pandas as pd


# ======================================================
# LOGGING
# ======================================================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)-8s | %(message)s",
    datefmt="%H:%M:%S"
)
log = logging.getLogger("NEURO_PIPELINE")


# ======================================================
# CONFIG
# ======================================================
PROGRESS_FILE = "progress.json"


# ======================================================
# UTILIDADES
# ======================================================
def sanitize(text):
    return "".join(c if c.isalnum() or c in "._-" else "_" for c in str(text))


def sha256(path):
    h = hashlib.sha256()
    with open(path, "rb") as f:
        for chunk in iter(lambda: f.read(8192), b""):
            h.update(chunk)
    return h.hexdigest()


def is_dicom(path):
    try:
        pydicom.dcmread(path, stop_before_pixels=True)
        return True
    except Exception:
        return False


# ======================================================
# DISCOVERY
# ======================================================
def find_dicomdirs(root):
    dicomdirs = []
    for r, _, fs in os.walk(root):
        for f in fs:
            if f.upper() == "DICOMDIR":
                dicomdirs.append(os.path.join(r, f))
    return sorted(dicomdirs)


def find_dicom_files(base_dir):
    files = []
    for r, _, fs in os.walk(base_dir):
        for f in fs:
            p = os.path.join(r, f)
            if f.upper() != "DICOMDIR" and is_dicom(p):
                files.append(p)
    return files


# ======================================================
# FILTROS CL√çNICOS
# ======================================================
def is_valid_volume(dcm):
    desc = getattr(dcm, "SeriesDescription", "").upper()
    modality = getattr(dcm, "Modality", "").upper()

    blacklist = ["SCOUT", "LOCALIZER", "LOC", "TOPOGRAM"]

    if modality not in ("CT", "MR"):
        return False

    if any(b in desc for b in blacklist):
        return False

    return True


# ======================================================
# VALIDA√á√ÉO DE DIMENS√ïES
# ======================================================
def get_image_dimensions(dicom_path):
    """Retorna as dimens√µes (linhas, colunas) de uma imagem DICOM."""
    try:
        dcm = pydicom.dcmread(dicom_path, stop_before_pixels=True)
        rows = int(getattr(dcm, "Rows", 0))
        cols = int(getattr(dcm, "Columns", 0))
        return (rows, cols)
    except Exception:
        return None


def filter_consistent_dimensions(files):
    """Filtra arquivos mantendo apenas aqueles com a dimens√£o mais comum."""
    dimensions_count = defaultdict(list)
    
    for f in files:
        dims = get_image_dimensions(f)
        if dims:
            dimensions_count[dims].append(f)
    
    if not dimensions_count:
        return files, None
    
    # Encontra a dimens√£o mais comum
    most_common_dim = max(dimensions_count.keys(), key=lambda d: len(dimensions_count[d]))
    filtered_files = dimensions_count[most_common_dim]
    
    removed_count = len(files) - len(filtered_files)
    
    return filtered_files, (removed_count, most_common_dim) if removed_count > 0 else None


# ======================================================
# CONVERS√ÉO ROBUSTA
# ======================================================
def dicom_series_to_nifti(files):
    reader = sitk.ImageSeriesReader()
    reader.SetFileNames(files)
    img = reader.Execute()

    img = sitk.Cast(img, sitk.sitkInt16)

    fixed = sitk.Image(img)
    fixed.SetSpacing(img.GetSpacing())
    fixed.SetOrigin(img.GetOrigin())
    fixed.SetDirection(img.GetDirection())

    return fixed


# ======================================================
# CHECKPOINT
# ======================================================
def load_progress(output_dir):
    path = os.path.join(output_dir, PROGRESS_FILE)
    if os.path.exists(path):
        with open(path, "r") as f:
            return json.load(f)
    return {"completed": []}


def save_progress(output_dir, progress):
    path = os.path.join(output_dir, PROGRESS_FILE)
    with open(path, "w") as f:
        json.dump(progress, f, indent=2)


# ======================================================
# PROCESSA UM DICOMDIR
# ======================================================
def process_dicomdir(dicomdir, output_dir, metadata_rows):
    base_dir = os.path.dirname(dicomdir)
    log.info(f"üìÇ Processando DICOMDIR: {dicomdir}")

    files = find_dicom_files(base_dir)
    log.info(f"üìÅ DICOMs encontrados: {len(files)}")

    series = defaultdict(list)
    meta = {}

    for f in files:
        try:
            dcm = pydicom.dcmread(f, stop_before_pixels=True)
            if not is_valid_volume(dcm):
                continue

            uid = sanitize(dcm.SeriesInstanceUID)
            series[uid].append(f)

            meta[uid] = {
                "patient_id": sanitize(getattr(dcm, "PatientID", "UNKNOWN")),
                "modality": dcm.Modality,
                "study_uid": dcm.StudyInstanceUID
            }
        except Exception:
            continue

    log.info(f"üß† S√©ries v√°lidas: {len(series)}")

    for uid, files in series.items():
        if len(files) < 10:
            continue

        try:
            # Filtrar imagens com dimens√µes consistentes
            files, filter_info = filter_consistent_dimensions(files)
            
            if filter_info:
                removed, dims = filter_info
                log.warning(f"‚ö†Ô∏è  {removed} imagem(ns) removida(s) por dimens√µes inconsistentes. Mantendo: {dims}")
            
            if len(files) < 10:
                log.warning(f"‚ö†Ô∏è  S√©rie {uid} ignorada: menos de 10 imagens ap√≥s filtragem")
                continue

            files.sort(
                key=lambda x: float(
                    pydicom.dcmread(
                        x, stop_before_pixels=True
                    ).get("ImagePositionPatient", [0, 0, 0])[2]
                )
            )

            img = dicom_series_to_nifti(files)

            name = f"{meta[uid]['patient_id']}_{meta[uid]['modality']}_{uid}.nii.gz"
            out = os.path.join(output_dir, name)

            sitk.WriteImage(img, out, True)

            nii = nib.load(out)

            metadata_rows.append({
                "filename": name,
                "patient_id": meta[uid]["patient_id"],
                "modality": meta[uid]["modality"],
                "series_uid": uid,
                "study_uid": meta[uid]["study_uid"],
                "shape": nii.shape,
                "spacing": nii.header.get_zooms(),
                "sha256": sha256(out)
            })

            log.info(f"‚úÖ S√©rie convertida: {name}")
        
        except Exception as e:
            log.error(f"‚ùå Erro ao processar s√©rie {uid}: {e}")
            continue


# ======================================================
# PIPELINE PRINCIPAL (COM RESUME)
# ======================================================
def run_pipeline(root_dir, output_dir):
    os.makedirs(output_dir, exist_ok=True)

    progress = load_progress(output_dir)
    completed = set(progress["completed"])

    dicomdirs = find_dicomdirs(root_dir)
    log.info(f"üîé DICOMDIRs encontrados: {len(dicomdirs)}")

    metadata_rows = []

    for idx, dicomdir in enumerate(dicomdirs, 1):
        if dicomdir in completed:
            log.info(f"‚è≠Ô∏è [{idx}/{len(dicomdirs)}] J√° processado ‚Äî pulando")
            continue

        log.info(f"\n===== [{idx}/{len(dicomdirs)}] NOVO DICOMDIR =====")

        try:
            process_dicomdir(dicomdir, output_dir, metadata_rows)

            completed.add(dicomdir)
            progress["completed"] = list(completed)
            save_progress(output_dir, progress)

            log.info("üíæ Checkpoint salvo")

        except Exception as e:
            log.error(f"‚ùå Erro no DICOMDIR {dicomdir}: {e}")
            log.info("‚ö†Ô∏è Continuando com pr√≥ximo DICOMDIR...")
            continue

    # Salvar metadados finais
    if metadata_rows:
        csv_path = os.path.join(output_dir, "metadata.csv")
        pd.DataFrame(metadata_rows).to_csv(csv_path, index=False)
        log.info(f"üìÑ Metadados exportados: {csv_path}")

    log.info("üèÅ PIPELINE FINALIZADO")


# ======================================================
# EXECU√á√ÉO
# ======================================================
if __name__ == "__main__":
    ROOT = r"C:\Users\F8944859\Downloads\DICOM"
    OUT = r"C:\Users\F8944859\Downloads\NIfTI"

    run_pipeline(ROOT, OUT)
